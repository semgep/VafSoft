
<!DOCTYPE html> <html> <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects</title>
    <link rel="stylesheet" href="styles.css">
    <script src="scripts.js"></script>
    </head> 
    <body> 
   
    <div id = "Projects" class="main">
    <header>
   <div class="menu-icon" onclick="toggleMenu()">&#9776;</div>
    <div class="header-content"><div class="header-row"><h3>Sergei Gepshtein's Portal</h3></div><br>
    <div class="header-second-row"> <h3>Projects</h3> </div><br></div> </header>
   <nav id="menu" class="hidden"><div class="close-menu" onclick="toggleMenu()">&times;</div>
   <ul> <li><a href="About.html">About</a></li> <li><a href="Publications.html">Publications</a></li><li><a href="Projects.html">Projects</a></li> </ul> </nav>
   <span>
   <div class="common">
   <div id="Article_2" class = "article"><span class="title"> Learning in the Museum</span><p> National Science Foundation 2022-2025 </p><p> In a synthesis of science and art, Salk scientists have teamed up with curators and design experts at the Los Angeles County Museum of Art (LACMA) to study how nearly 100,000 museum visitors respond to exhibition design. The goal of the project is to better understand how people perceive, make choices in, interact with, and learn from a complex environment, and to further enhance the educational mission of museums through evidence-based design strategies. </p>
   <button id="Button_2a" onclick="toggle(this);"> [+] Citation</button>
   <button id="Button_2b" onclick="toggle(this);"> [+] Description</button>
   <button id="Button_2c" onclick="toggle(this);"> [+] Links</button>
   
   <p class="text"  id="Text_2a"> 
   <span><font size='3'> Thomas D. Albright, Sergei Gepshtein, Talmo Pereira<br>Perception, Behavior and Learning in the Museum &nbsp;<br>National Science Foundation&nbsp;2022-2025
   <p style="display:none;"   id="Text_2b"> In addition to their traditional role as a source of emotional rewards and inspiration, the modern mission of art museums is education. Objects of interest are presented in the context of a narrative that the museum visitor follows to learn history, materials, technique, and function, as well as relationships to the natural world and human civilization. Narrative principles for exhibition design have for decades emerged from small scale observational studies of museum visitor behaviors, such as expressions of engagement and choice of path. Building on recent advances in scientific understanding of sensory processing and behavioral choice, in combination with sophisticated computational tools for characterization of fine details of behavior, a team of scientists and museum professionals will turn a designated gallery at the Los Angeles County Museum of Art into a laboratory for investigation of human perception, action, choice, and learning. The broad applied goal of this project is to obtain scientific knowledge that will further enhance the educational mission of museums. The intellectual impact of the project will be an improved understanding of environmental and social factors that guide human behavior under naturalistic conditions. More generally, the project will benefit the larger communities of architecture and design professionals, as a model of experimental methodology and by offering a unique multifaceted dataset for analysis and evaluation of the influence of the built environment.
   
   The project builds upon several technological and computational innovations. One is the methods of computational ethology, which is a new approach to quantitative behavioral analysis that employs high-resolution 3D motion capture together with machine learning methods for behavioral classification. This approach will yield efficient non-invasive measurements of visitor locations, rates of movement, poses, social interactions, gestures and expressions that reflect transitory cognitive states, such as visual attention and engagement with works of art. Observations from tens of thousands of anonymous museum visitors will be subjected to descriptive statistical analyses, to gain insights into the relationship between the structure and content of exhibition design and the behavior of individuals and social groups, and to discover spatial and temporal contingencies between visitor behaviors at different locations in the gallery. Results of these descriptive analyses will be used to develop predictive models of visitor behavior, capturing the full gamut of individual styles of visitor interaction with works of art and other visitors, informed by visitors’ sensory operating characteristics as well as sensory and motoric affordances of the gallery space. In the final stage of the project, strategic modifications to gallery design will be used to test and further develop predictive models in forecasting visitor behaviors. Results will constitute a new empirical framework for exhibition design and its impact on visitor experience. </p>
   <p style="display:none;" id="Text_2c">
   <span> &#9679; <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2217975">Publisher link</a> </span><br>
   <span> &#9679; <a href=" https://www.salk.edu/news-release/salk-institute-and-los-angeles-county-museum-of-art-team-up-to-study-museum-visitor-behavior/">Publisher link</a> </span><br>
    <hr></div>
   <div id="Article_3" class = "article"><span class="title">Neural mechanisms of visual sensitivity</span><p> National Institutes of Health 2019-2024 </p><p> The long-term goal of this project is to contribute to the understanding of biological substrates of visual perception. Detailed knowledge of normal functions of visual cortex shall provide insights into neural events that underlie visual sensitivity and the effects of visual experience, which will ultimately aid the treatment and prevention of neurologic and neuropsychiatric disorders of vision. These aims are pertinent to development and use of prosthetic and behavioral therapies for the visually handicapped. </p>
   <button id="Button_3a" onclick="toggle(this);"> [+] Citation</button>
   <button id="Button_3b" onclick="toggle(this);"> [+] Description</button>
   <button id="Button_3c" onclick="toggle(this);"> [+] Links</button>
   
   <p class="text"  id="Text_3a"> 
   <span><font size='3'> Thomas D. Albright, Sergei Gepshtein<br>Neural mechanisms of visual sensitivity&nbsp;<br>National Institutes of Health&nbsp;2019-2024
   <p style="display:none;"   id="Text_3b"> One of the most important questions in neuroscience today concerns the mechanisms by which sensory neurons give rise to perceptual experience. There are many ways to address this question, which have long populated the field of visual neuroscience. Prominent among them is the study of visual selectivity. Observers are highly sensitive to some visual stimuli and less sensitive to others. Visual neurons are also highly selective: Each responds to a limited range of stimuli along several stimulus dimensions. We aim to understand how the selective pattern of neuronal responses accounts for the observer's selective perceptual experience and discriminative capacity. This understanding is achieved through experiments that first evaluate patterns of neuronal selectivity for visual stimuli that vary in their spatial and temporal properties. Second, these data, in combination with manipulations of stimulus context, are used to develop a novel mechanistic account of neuronal selectivity based on activity within cortical visual circuits stabilized by inhibition. Finally, to understand how neuronal selectivity underlies perceptual experience, direct comparisons will be made between physiological measures of neuronal selectivity and behavioral measures of perceptual selectivity, assessed concurrently under identical conditions. The experiments will yield an unprecedented body of comprehensive data regarding the spatiotemporal tuning of the primate visual system. These data will be used to further understanding of the mechanisms of sensory processing and will provide insights into pathologies of vision caused by trauma, disease and developmental disorders of the brain. </p>
   <p style="display:none;" id="Text_3c">
   <span> &#9679; <a href="https://grantome.com/grant/NIH/R01-EY029117-02">Publisher link</a> </span><br>
    <hr></div>
   <div id="Article_4" class = "article"><span class="title">A Perceptual Scaling Approach to Eyewitness Identification</span><p> National Science Foundation 2021-2024 </p><p> We attack a longstanding issue in the criminal justice system—a pervasive form of human error with tragic personal and societal consequences. It concerns eyewitness identification in police lineups, where a suspect's facial image is presented alongside facial images of several innocent individuals known as “fillers.” Building on an innovative approach to conducting eyewitness lineups, and on tools of machine learning, we propose a novel solution for selecting “fair” lineups that enhance discriminability between the culprit and innocent suspects.  </p>
   <button id="Button_4a" onclick="toggle(this);"> [+] Citation</button>
   <button id="Button_4b" onclick="toggle(this);"> [+] Description</button>
   <button id="Button_4c" onclick="toggle(this);"> [+] Links</button>
   
   <p class="text"  id="Text_4a"> 
   <span><font size='3'> Thomas D. Albright, Sergei Gepshtein<br>A Perceptual Scaling Approach to Eyewitness Identification&nbsp;<br>National Science Foundation&nbsp;2021-2024
   <p style="display:none;"   id="Text_4b"> Eyewitness identification has long played an important role in criminal investigations and prosecutions, where identifying the culprit is critical to the criminal justice process. Based on advances in understanding of perception and memory, this project will examine the role of “fillers” in lineups. Fillers are the individuals in a lineup known to be innocent who serve to challenge eyewitness recognition. The research will develop a novel method for filler selection based on a combination of human and machine measures of facial similarity. 
   The project builds upon a new paradigm for the design and conduct of lineups for eyewitness identification. Drawing upon perceptual scaling, well-established in sensory psychology, this approach will be used to estimate the strength of eyewitness memories, and thus to generate large libraries of facial images in which the degree of facial similarity is quantified. This work will help to reduce susceptibility of the eyewitness to decision bias and will provide quantitative measures of the perceived similarity of faces. These measures, in combination with a machine learning algorithm, will be used to create a Model Witness, which is an algorithm that reproduces similarity judgements of human observers and predicts perceptual similarity for new faces. The project will yield an objective system for selecting fillers in order to optimize eyewitness fairness and performance.
    </p>
   <p style="display:none;" id="Text_4c">
   <span> &#9679; <a href="https://app.dimensions.ai/details/grant/grant.9605705">Publisher link</a> </span><br>
    <hr></div>
   <div id="Article_5" class = "article"><span class="title">Vision Science for Dynamic Architecture</span><p> Academy of Neuroscience for Architeture 2013-2014 </p><p> This project is a collaboration between several disciplines: neuroscience and psychophysics (Gepshtein), production design and world building (McDowell), architectural and urban design (Lynn). Using the computational and experimental tools developed in the context of scientific investigation, the stydy will reveal the visual organization of the spaces generated by specific built environments. </p>
   <button id="Button_5a" onclick="toggle(this);"> [+] Citation</button>
   <button id="Button_5b" onclick="toggle(this);"> [+] Description</button>
   <button id="Button_5c" onclick="toggle(this);"> [+] Links</button>
   
   <p class="text"  id="Text_5a"> 
   <span><font size='3'> Sergei Gepshtein, Alex McDoweell, Greg Lynn<br>Vision Science for Dynamic Architecture&nbsp;<br>Academy of Neuroscience for Architeture&nbsp;2013-2014
   <p style="display:none;"   id="Text_5b"> The relationship between the person and the built environment is dynamic. This dynamism unfolds over many spatial and temporal scales. Consider the varying viewing distances and angles of observation, and also the built environments that contain moving parts and moving pictures. The architect wants to predict human responses for the full range of these possibilities: a daunting task. We study how this challenge can be reduced using the systematic understanding of perception by sensory neuroscience. </p>
   <p style="display:none;" id="Text_5c">
   <span> &#9679; <a href="http://vcl.salk.edu/~gepshtein/Hay/">Publisher link</a> </span><br>
    <hr></div>
   <div id="Article_6" class = "article"><span class="title">Gestalt Detection</span><p> National Science Foundation 2010-2013 </p><p> Perceptual grouping organizes elements of visual stimulation into coherent scenes, a process that can be both involuntary and voluntary, contributing to our understanding of visual awareness of the world. The aim of this work is to clarify the fundamental processes of perceptual grouping through rigorous measurement and modeling, starting with simple patterns to study individual grouping forces and progressing to more complex patterns to derive general quantitative laws of perceptual organization. </p>
   <button id="Button_6a" onclick="toggle(this);"> [+] Citation</button>
   <button id="Button_6b" onclick="toggle(this);"> [+] Description</button>
   <button id="Button_6c" onclick="toggle(this);"> [+] Links</button>
   
   <p class="text"  id="Text_6a"> 
   <span><font size='3'> Sergei Gepshtein, Michael Kubovy<br>Gestalt Detection&nbsp;<br>National Science Foundation&nbsp;2010-2013
   <p style="display:none;"   id="Text_6b"> When we look at the world, how do we know which parts of the visual input belong to the same object and which do not? The process known as perceptual grouping takes elements of the visual input and combines them into what we experience as a visual scene that contains objects, people, plants, shadows, and so on. Most of the time perceptual grouping is involuntary but it can come under voluntary control. For this reason, the study of perceptual grouping is a part of the larger effort toward understanding consciousness. Although phenomena of perceptual grouping are an essential foundation of perception, they are often described using a list of qualitative "principles," such as proximity, similarity, and good continuation, that are vague and unquantified. Michael Kubovy at the University of Virginia and Sergei Gepshtein at the Salk Institute for Biological Studies are proposing to clarify some of the fundamental processes of perceptual grouping, using rigorous methods of measurement and modeling. The researchers start with simple visual patterns that allow them to study one force of perceptual grouping at a time. The individual forces of grouping will then be combined, using more complex visual patterns, with the goal to derive general quantitative laws of perceptual grouping. The researchers will study the interaction of geometric factors (such as proximity between elements of visual displays) and intensive factors (such as the luminance and contrast of the elements) in perceptual grouping. The laws of combination of grouping factors will be compared with the laws of combination of other sensory cues, which have been intensively studied in the perception of visual depth and in multisensory integration. Software to be developed for this research program will be made accessible to the public. In addition to addressing fundamental issues in visual perception, the work has the potential to influence developments in visual media such as art, animation, and film. </p>
   <p style="display:none;" id="Text_6c">
   <span> &#9679; <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1027259">Publisher link</a> </span><br>
    <hr></div>
   <div id="Article_7" class = "article"><span class="title">Towards an economic theory of neural function</span><p>  The Swartz Foundation 2009-2011 </p><p> For a long time, researchers expected that visual adaptation ought to improve visual sensitivity to the prevailing properties of the world. But empirical studies found that the sensitivity to adapting visual stimuli sometimes increased, sometimes decreased, and sometimes it did not change at all. Here we propose a resolution to this controversy. </p>
   <button id="Button_7a" onclick="toggle(this);"> [+] Citation</button>
   <button id="Button_7b" onclick="toggle(this);"> [+] Description</button>
   <button id="Button_7c" onclick="toggle(this);"> [+] Links</button>
   
   <p class="text"  id="Text_7a"> 
   <span><font size='3'> Sergei Gepshtein<br>Towards an economic theory of neural function&nbsp;<br>The Swartz Foundation for Theoretical Neuroscience &nbsp;2009-2011
   <p style="display:none;"   id="Text_7b"> A central theme of this work is a new economic approach to sensory function. The approach is economic because it rests on a basic fact that neuronal systems have limited resources in their disposal, creating the pressure to use the same resource for multiple tasks. Since every single resource (an individual neuron or a network) has limited capabilities, biological sensory systems face the challenge of resource allocation: how to distribute the different resources to potential stimuli, in view of the varying demands of the organism and highly variable environment. Starting with some very basic constraints of sensory measurement, such as the uncertainty principle of measurement, we derive prescriptions of optimal resources allocation in the variable environment and predict consequences of such allocation for sensory behavior.  </p>
   <p style="display:none;" id="Text_7c">
   <span> &#9679; <a href="https://www.theswartzfoundation.org/">Publisher link</a> </span><br>
    <hr></div>
   ></div>
   <div><font size="1" face="Calibri">Updated in July 12, 2024 at 1:05 PM PDT</font> </div
   </body></html>
